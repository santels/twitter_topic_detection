cdef extern from "math.h":
    double sqrt(double m)

import re
import sqlite3
import numpy as np
cimport numpy as np
cimport cython

from nltk.corpus import wordnet as wn
from sklearn.feature_extraction.text import TfidfVectorizer


conn = sqlite3.connect('.word_scores.db')
cur = conn.cursor()
THRESHOLD = 0.82


cdef class Similarity:
    """
    Document Similarity Measure class implementing Soft Cosine Measure and
    using WordNet's wup_similarity function for getting feature similarity
    score.
    """
    def __init__(self, tokens):
        """
        Similarity class constructor.
        """
        self.initialize(tokens)

    def initialize(self, tokens):
        """
        Utility function to initialize and setup database connection and
        get TF-IDF values of documents and its features.
        """
        tfidf = TfidfVectorizer(tokenizer=lambda keys: tokens[keys])
        self.matrix = tfidf.fit_transform(tokens.keys()).A

        self._features = tfidf.get_feature_names()
        conn.execute("DROP TABLE IF EXISTS tblWord")
        conn.execute("CREATE TABLE tblWord(wordPair UNIQUE, score DOUBLE)")

    def get_features(self):
        """
        Gets list of features generated by the tf-idf vectorizer.
        (This is created because of the cdef declaration which does not allow
        other Python modules to access C-type variables).
        """
        return self._features

    def similarity(self, M1=None, M2=None, scoring=False):
        """
        Similarity function wrapper. This is what will be called by other
        modules.
        """
        if M1 is None:
            M1 = self.matrix
            if M2 is None:
                M2 = self.matrix
        scoring = 0 if not scoring else 1
        return self._similarity(M1, M2, scoring)

    @cython.wraparound(False)
    @cython.boundscheck(False)
    cdef np.ndarray[DOUBLE_t, ndim=2] _similarity(self,
            np.ndarray[DOUBLE_t, ndim=2] M1, np.ndarray[DOUBLE_t, ndim=2] M2,
            int is_scoring):
        """
        Calculates similarity measure of each document matrix. Uses soft cosine
        similarity measure to calculate document similarities.
        """
        cdef:
            int M1_len = M1.shape[0]
            int M2_len = M2.shape[0]
            int i, j

        # Get the sum of consecutive integers for the size of the array
        cdef np.ndarray[DOUBLE_t, ndim=2] doc_sim = np.zeros([M1_len, M2_len])

        for i in range(M1_len):
            for j in range(M2_len):
                if is_scoring:
                    doc_sim[i, j] = self._soft_cosine_similarity(M1[i],
                                                                 M2[j])
                else:
                    if i == j:
                        doc_sim[i, j] = 1.0
                    else:
                        doc_sim[i, j] = self._soft_cosine_similarity(M1[i],
                                                                     M2[j])
        return doc_sim

    def cos_similarity(self, M1=None, M2=None):
        '''
        Cosine similarity measure of documents. For testing purposes.
        '''
        from sklearn.metrics.pairwise import cosine_similarity
        if M1 is None:
            M1 = self.matrix
            if M2 is None:
                M2 = self.matrix
        return cosine_similarity(M1, M2)

    cdef DOUBLE_t _multiply_elements(self, np.ndarray[DOUBLE_t, ndim=1] v1,
            np.ndarray[DOUBLE_t, ndim=1] v2):
        """
        Multiplies values between vector elements and similarity function
        scores.
        """
        cdef:
            DOUBLE_t total_score = 0.0
            object v1nz = iter(v1.nonzero()[0])
            object v2nz = iter(v2.nonzero()[0])
            int i, j

        for i in v1nz:
            for j in v2nz:
                total_score += v1[i] * v2[j] * self._get_score(
                    self._features[i], self._features[j])
        return total_score

    @cython.cdivision(True)
    cdef DOUBLE_t _soft_cosine_similarity(self, np.ndarray[DOUBLE_t, ndim=1] v1,
            np.ndarray[DOUBLE_t, ndim=1] v2):
        """
        Soft Cosine Similarity Measure
        ------------------------------
        Traditional Cosine Similarity Measure that takes into account the
        semantic similarities of each features in each documents.
        """
        cdef DOUBLE_t product = self._multiply_elements(v1, v2)
        cdef DOUBLE_t denom1 = sqrt(self._multiply_elements(v1, v1))
        cdef DOUBLE_t denom2 = sqrt(self._multiply_elements(v2, v2))

        if denom1 == 0.0 or denom2 == 0.0:
            return 0.0

        return product / (denom1 * denom2)

    cdef DOUBLE_t _get_score(self, str feature1, str feature2):
        """
        Gets and filters feature score and ignores score less than the
        specified threshold.
        """
        cdef DOUBLE_t feature_score = 0.0
        cdef str word_pair

        # Same terms have 1.0 similarity.
        if feature1 == feature2:
            feature_score = 1.0
        else:
            feature_score = self._get_feature_score(feature1,
                    feature2)
            if feature_score < THRESHOLD:
                feature_score = 0.0

            word_pair = ' '.join(sorted([feature1, feature2]))
            try:
                conn.execute('''
                    INSERT INTO tblWord(wordPair, score) VALUES (?, ?)
                    ''',
                    (word_pair, feature_score))
            except:
                pass

        return feature_score

    cdef tuple _get_synsets(self, str term1, str term2):
        """
        Gets best synsets of each term based on the highest path similarity
        among all pairs compared; if the synset's pos() is not a noun or verb,
        it gets its related nouns/forms.
        """
        cdef list synset_list1 = wn.synsets(term1)
        cdef list synset_list2 = wn.synsets(term2)

        if (len(synset_list1) == 0) or (len(synset_list2) == 0):
            return None, None

        return (synset_list1[0], synset_list2[0])

    cdef DOUBLE_t _get_feature_score(self, str term1, str term2):
        """
        If term1 and term2 are synsets, returns their similarity score. If they
        are lists, gets all similarity scores of each element and returns the
        best score.
        """
        cdef tuple sorted_terms
        cdef DOUBLE_t score

        term1, term2 = tuple(sorted((term1, term2)))
        sorted_terms = (term1, term2)

        # Checks if synset pair has already been calculated.
        cur.execute("SELECT score FROM tblWord WHERE wordPair=?",
                (' '.join(sorted_terms),))
        _score = cur.fetchone()
        if _score:
            score = _score[0]
            return score

        # If a term contains a hashtag, it automatically does not contain
        # synsets, thus, returning 0.
        if any("#" in term for term in sorted_terms):
            return 0.0

        # If a term does not fully contains alpha characters, it has no
        # synsets.
        if any(re.search(r'^([a-zA-Z]+[-]?[a-zA-Z]+)$', term) is None
               for term in sorted_terms):
            return 0.0

        cdef tuple synsets = self._get_synsets(term1, term2)

        # Checks if one/both synset/s is/are not found in WordNet. If it's not
        # found, its value is None, otherwise, caches the Synset object.
        if synsets[0] is None or synsets[1] is None:
            return 0.0

        # Checks if both synsets are VERB. If so, will skip getting the
        # similarity.
        #if synsets[0].pos() == 'v' and synsets[1].pos() == 'v':
        #    return 0.0

        _score = wn.wup_similarity(synsets[0], synsets[1])

        if _score is None:
            score = 0.0
        else:
            score = _score
        return score
